{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edef987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import socket, pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "os.environ['ROOT_DATA_DIR']='/work/handong28/database'\n",
    "path = os.getcwd()\n",
    "path = path.split('/')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.cpp_extension import CUDA_HOME\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from core.data_loader_type import DataLoaderType\n",
    "from core.enum import DataType\n",
    "from core.loss_type import BlockAggregationMode, LossType\n",
    "from core.model_type import ModelType\n",
    "from data_loaders.pl_data_loader_module import PLDataLoader\n",
    "from utils.run_utils import get_model, parse_date_end, parse_date_start, parse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a19787",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(socket.gethostname(), datetime.now().strftime(\"%y-%m-%d-%H:%M:%S\"))\n",
    "print('Python version', sys.version)\n",
    "print('CUDA_HOME', CUDA_HOME)\n",
    "print('CudaToolKit Version', torch.version.cuda)\n",
    "print('torch Version', torch.__version__)\n",
    "print('torchvision Version', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser() #--代表是optional\n",
    "# 若在命令列有輸入值，才會進行「type」的運算（預設string）；若無，直接回傳default\n",
    "parser.add_argument('--dloader_type', type=DataLoaderType.from_name, default=DataLoaderType.Native)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--train_start', type=parse_date_start, default=datetime(2015, 1, 1))\n",
    "parser.add_argument('--train_end', type=parse_date_end, default=datetime(2015, 12, 31, 23, 50))\n",
    "parser.add_argument('--val_start', type=parse_date_start, default=datetime(2018, 1, 1))\n",
    "parser.add_argument('--val_end', type=parse_date_end, default=datetime(2018, 12, 31, 23, 50))\n",
    "parser.add_argument('--loss_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--log_dir', type=str, default='logs')\n",
    "parser.add_argument('--data_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--model_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--checkpoints_path',\n",
    "                    type=str,\n",
    "                    default=('/'.join(path) + '/training/checkpoints/'),\n",
    "                    help='Full path to the directory where model checkpoints are [to be] saved')\n",
    "# 加入Trainer參數\n",
    "parser = Trainer.add_argparse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d60a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.parse_args()\n",
    "# args = parser.parse_args(['--gpus','2',\n",
    "#                           '--accelerator','dp',\n",
    "#                           '--batch_size','8'])# 回傳一個args就可以用了\n",
    "args = parser.parse_args(['--batch_size','32',\n",
    "                          '--data_kwargs','sampling_rate:6,hetero_data:0,target_len:3',\n",
    "                          '--model_kwargs','type:BalancedGRUAdvPONI,teach_force:0.5'\n",
    "                         ])\n",
    "print('dloader_type:',args.dloader_type,'\\n'\n",
    "      'data_kwargs:',args.data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd817c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "workers = 8\n",
    "input_shape = (120, 120)\n",
    "loss_type = int(args.loss_kwargs.get('type', LossType.WeightedMAE))\n",
    "loss_aggregation_mode = int(args.loss_kwargs.get('aggregation_mode', BlockAggregationMode.MAX))\n",
    "loss_kernel_size = int(args.loss_kwargs.get('kernel_size', 5))\n",
    "residual_loss = bool(int(args.loss_kwargs.get('residual_loss', 0)))\n",
    "mixing_weight = float(args.loss_kwargs.get('w', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215285d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kwargs = {\n",
    "    'type': loss_type,\n",
    "    'aggregation_mode': loss_aggregation_mode,\n",
    "    'kernel_size': loss_kernel_size,\n",
    "    'residual_loss': residual_loss,\n",
    "    'w': mixing_weight\n",
    "}\n",
    "if loss_type in [LossType.SSIMBasedLoss, LossType.NormalizedSSIMBasedLoss]:\n",
    "    loss_kwargs['mae_w'] = float(args.loss_kwargs.get('mae_w', 0.1))\n",
    "    loss_kwargs['ssim_w'] = float(args.loss_kwargs.get('ssim_w', 0.02))\n",
    "\n",
    "data_kwargs = {\n",
    "    'data_type': int(args.data_kwargs.get('type', DataType.Rain+DataType.Radar)),\n",
    "    'residual': bool(int(args.data_kwargs.get('residual', 0))),\n",
    "    'target_offset': int(args.data_kwargs.get('target_offset', 0)),\n",
    "    'target_len': int(args.data_kwargs.get('target_len', 3)),\n",
    "    'input_len': int(args.data_kwargs.get('input_len', 6)),\n",
    "    'hourly_data': bool(int(args.data_kwargs.get('hourly_data', 0))),\n",
    "    'hetero_data': bool(int(args.data_kwargs.get('hetero_data', 0))),\n",
    "    'sampling_rate': int(args.data_kwargs.get('sampling_rate', 5)),\n",
    "    'prior_dtype': int(args.data_kwargs.get('prior', DataType.NoneAtAll)),\n",
    "    'random_std': int(args.data_kwargs.get('random_std', 0)),\n",
    "    'ith_grid': int(args.data_kwargs.get('ith_grid', -1)),\n",
    "    'pad_grid': int(args.data_kwargs.get('pad_grid', 10)),\n",
    "    'threshold': float(args.data_kwargs.get('threshold', 0.5)),\n",
    "}\n",
    "model_kwargs = {\n",
    "    'adv_w': float(args.model_kwargs.get('adv_w', 0.01)),\n",
    "    'model_type': ModelType.from_name(args.model_kwargs.get('type', 'BalancedGRUAdverserialAttention')),\n",
    "    'dis_d': int(args.model_kwargs.get('dis_d', 3)),\n",
    "    'teach_force':float(args.model_kwargs.get('teach_force', 0)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ecb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = PLDataLoader(\n",
    "    args.train_start,\n",
    "    args.train_end,\n",
    "    args.val_start,\n",
    "    args.val_end,\n",
    "    img_size=input_shape,\n",
    "    dloader_type=args.dloader_type,\n",
    "    **data_kwargs,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    args.train_start,\n",
    "    args.train_end,\n",
    "    model_kwargs,\n",
    "    loss_kwargs,\n",
    "    data_kwargs,\n",
    "    args.checkpoints_path,\n",
    "    args.log_dir,\n",
    "    data_loader_info=dm.model_related_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logger = TensorBoardLogger(save_dir='logs', name=ModelType.name(model_kwargs['model_type']))\n",
    "logger = TestTubeLogger(save_dir='logs', name=ModelType.name(model_kwargs['model_type']))\n",
    "logger.experiment.argparse(args)\n",
    "logger.experiment.tag({'input_len': data_kwargs['input_len'], 'target_len': data_kwargs['target_len']})\n",
    "trainer = Trainer.from_argparse_args(args, \n",
    "                                     gpus=1,\n",
    "                                     max_epochs=15, \n",
    "                                     fast_dev_run=False, \n",
    "                                     checkpoint_callback=model.get_checkpoint_callback(), \n",
    "                                     logger=logger,\n",
    "                                     callbacks=[EarlyStopping(monitor=\"val_loss\")])\n",
    "trainer.fit(model, dm)  #.fit同時做了train and validation\n",
    "#default max epochs for pl is 1000\n",
    "\n",
    "# if args.evaluate_ckp_path:\n",
    "#     checkpoint = torch.load(args.evaluate_ckp_path)\n",
    "#     _ = model.load_state_dict(checkpoint['state_dict'])\n",
    "#     trainer.test(model, test_dataloaders=dm.val_dataloader())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3_hetero (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
